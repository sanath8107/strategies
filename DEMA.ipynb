{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DEMA.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOhceZDO1Q5gUqwnVOcNEVJ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sanath8107/strategies/blob/main/DEMA.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eLhnzxoxmLxK"
      },
      "source": [
        "\n",
        "# **DEMA(Double exponential moving average)**\n",
        "It depicts the trend in the graph.\n",
        "1. If the price falls below DEMA then a downward trend is about to happen\n",
        "2. If the price crosses the DEMA then the upward trend is about to happen\n",
        "\n",
        "Author(Sanath Ramesh)\n",
        "\n",
        "https://www.investopedia.com/terms/d/double-exponential-moving-average.asp\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pn96u0Hu9TMi"
      },
      "source": [
        "#**Strategy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGMGt-fNl7Q5"
      },
      "source": [
        "#######################  STRATEGY #######################\n",
        "\n",
        "def dema(data):\n",
        "    data = clean_data(data, 'close')\n",
        "    #calculate EMA\n",
        "    ema = data['close'].ewm(span=12, adjust=False).mean()\n",
        "    #calculate DEMA\n",
        "    dema_value = 2*ema - ema.ewm(span=12,adjust=False).mean()\n",
        "    df = pd.DataFrame(list(zip(dema_value)),\n",
        "                      columns=['dema'])\n",
        "    data  = pd.DataFrame(data)\n",
        "    print\n",
        "    buy = []\n",
        "    sell = []\n",
        "    flag = -1\n",
        "\n",
        "    for i in range(0, len(df)):\n",
        "        if df['dema'][i] > float(data['close'][i]):\n",
        "            buy.append(np.nan)\n",
        "            if flag != 1:\n",
        "                sell.append(data['close'][i])\n",
        "                flag = 1\n",
        "            else:\n",
        "                sell.append(np.nan)\n",
        "        elif df['dema'][i] < float(data['close'][i]):\n",
        "            sell.append(np.nan)\n",
        "            if flag != 0:\n",
        "                buy.append(data['close'][i])\n",
        "                flag = 0\n",
        "            else:\n",
        "                buy.append(np.nan)\n",
        "        else:\n",
        "            buy.append(np.nan)\n",
        "            sell.append(np.nan)\n",
        "    buy_sell_points = {'buy': buy, 'sell': sell}\n",
        "    return pd.DataFrame.from_dict(buy_sell_points)\n",
        "\n",
        "#########################################################\n"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7F9wPpeI9ba2"
      },
      "source": [
        "#**Get Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I79ows7s0CQQ"
      },
      "source": [
        "import sys\n",
        "\n",
        "import requests\n",
        "import csv\n",
        "import datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "cookie_url = 'https://www.nseindia.com/get-quotes/derivatives?symbol=BANKNIFTY'\n",
        "equity_base_url = 'https://www.nseindia.com/api/historical/cm/equity'\n",
        "headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) '\n",
        "                         'Chrome/87.0.4280.88 Safari/537.36'}\n",
        "\n",
        "\n",
        "def get_urls(scrip, from_date, to_date, instrument_type):\n",
        "    url_list = []\n",
        "\n",
        "    # temp_from_date = from_date\n",
        "    from_date = datetime.datetime.strptime(from_date, '%d-%m-%Y')\n",
        "    to_date = datetime.datetime.strptime(to_date, '%d-%m-%Y')\n",
        "\n",
        "    day_diff = (to_date - from_date).days\n",
        "    if day_diff < 0:\n",
        "        print(\"From date should be earlier\")\n",
        "        sys.exit(0)\n",
        "\n",
        "    temp_date = from_date + datetime.timedelta(days=365 * 2)\n",
        "    while temp_date <= to_date:\n",
        "        equity_data_url = equity_base_url\n",
        "        equity_data_url += '?' + 'symbol=' + scrip.upper()\n",
        "        equity_data_url += '&' + 'series=' + '[%22' + instrument_type + '%22]'\n",
        "        equity_data_url += '&' + 'from=' + from_date.strftime(\"%d-%m-%Y\")\n",
        "        equity_data_url += '&' + 'to=' + temp_date.strftime(\"%d-%m-%Y\")\n",
        "        equity_data_url += '&' + 'csv=true'\n",
        "        url_list.append(equity_data_url)\n",
        "        # print(equity_data_url)\n",
        "        from_date = temp_date\n",
        "        temp_date = from_date + datetime.timedelta(days=365 * 2)\n",
        "\n",
        "    equity_data_url = equity_base_url\n",
        "    equity_data_url += '?' + 'symbol=' + scrip.upper()\n",
        "    equity_data_url += '&' + 'series=' + '[%22' + instrument_type + '%22]'\n",
        "    equity_data_url += '&' + 'from=' + from_date.strftime(\"%d-%m-%Y\")\n",
        "    equity_data_url += '&' + 'to=' + to_date.strftime(\"%d-%m-%Y\")\n",
        "    equity_data_url += '&' + 'csv=true'\n",
        "    url_list.append(equity_data_url)\n",
        "    # print(equity_data_url)\n",
        "\n",
        "    return url_list\n",
        "\n",
        "\n",
        "def get_data(scrip, from_date, to_date, instrument_type):\n",
        "    url_list = get_urls(scrip, from_date, to_date, instrument_type)\n",
        "    full_data = []\n",
        "\n",
        "    with requests.session() as s:\n",
        "        # load cookies:\n",
        "        s.get(cookie_url, headers=headers)\n",
        "\n",
        "        for url in url_list:\n",
        "            _data = s.get(url, headers=headers)  # .json()\n",
        "            decoded_content = _data.content.decode('utf-8')\n",
        "            cr = csv.reader(decoded_content.splitlines(), delimiter=',')\n",
        "            my_list = list(cr)\n",
        "            my_list.reverse()\n",
        "            title_row = my_list.pop()\n",
        "            for row in my_list:\n",
        "                full_data.append(row)\n",
        "\n",
        "    # convert to dataframe\n",
        "    title_row[0] = \"Date\"\n",
        "    title_row = [title.strip().lower() for title in title_row]\n",
        "    full_data = pd.DataFrame(\n",
        "        data=full_data,\n",
        "        columns=title_row\n",
        "    )\n",
        "    full_data.set_index(pd.DatetimeIndex(full_data['date'].values))\n",
        "    print(\"Data collection complete, days =\", len(full_data))\n",
        "    return full_data\n",
        "\n",
        "def clean_data(data, which):\n",
        "    if which == 'close':\n",
        "        data['close'] = data['close'].apply(lambda x: x.replace(',',''))\n",
        "        return data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2a2DL-YI9pi4"
      },
      "source": [
        "# **Backtest and Result**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2sZQ0r10O0M"
      },
      "source": [
        "class Result():\n",
        "    def __init__(self, data, buy_sell):\n",
        "        self.profit = 0\n",
        "        self.profit_percentage = 0\n",
        "        self.true_positive = 0\n",
        "        self.false_positive = 0\n",
        "        self.true_negative = 0\n",
        "        self.false_negative = 0\n",
        "        self.data = data\n",
        "        self.buy_sell = buy_sell\n",
        "        self.run()\n",
        "\n",
        "    def run(self):\n",
        "        first_buy = self.buy_sell['buy'].first_valid_index()\n",
        "        last_sell = self.buy_sell['sell'].last_valid_index()\n",
        "        for i in range(first_buy, last_sell+1):\n",
        "            if self.buy_sell['buy'][i] is not np.nan and self.buy_sell['sell'][i] is np.nan:\n",
        "                self.profit -= float(self.buy_sell['buy'][i])\n",
        "            elif self.buy_sell['buy'][i] is np.nan and self.buy_sell['sell'][i] is not np.nan:\n",
        "                self.profit += float(self.buy_sell['sell'][i])\n",
        "\n",
        "\n",
        "def backtest(data, strategy, data_needed):\n",
        "    if not set(data_needed).issubset(set(data.columns)):\n",
        "        raise ValueError(\"data needed could not be collected\")\n",
        "    data_needed = data[data_needed]\n",
        "    buy_sell_points = strategy(data_needed)\n",
        "    result = Result(data, buy_sell_points)\n",
        "    return result"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SuJho3Sq91xB"
      },
      "source": [
        "# **Driver Code**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sE2ri5qA0PBA"
      },
      "source": [
        "data = get_data('WIPRO', '01-01-2017', '01-01-2018', 'EQ')\n",
        "\n",
        "try:\n",
        "    result = backtest(data, dema, ['date', 'close'])\n",
        "    print(\"Profit Generated: \", result.profit)\n",
        "except Exception as ex:\n",
        "    print(ex)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}